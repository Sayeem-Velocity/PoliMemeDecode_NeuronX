{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   PoliMeme Decode: Automated Political Meme Analysis\n",
    "# Model: Qwen2.5-VL-7B-Instruct | Method: Few-Shot Chain of Thought | Output: Structured JSON\n",
    "\n",
    "# Overview\n",
    "This notebook implements an automated pipeline to analyze Bangladeshi political and social memes. Using the Qwen2.5-VL Vision-Language Model (VLM), we extract semantic meaning, detect political intensity, and identify visual metaphors.\n",
    "\n",
    "# Key Features\n",
    "\n",
    "* 4-Bit Quantization: Optimized to run on Tesla T4 (16GB) GPUs.\n",
    "* Structured JSON Output: Enforces strict schema adherence for CSV generation.\n",
    "* Memory Management: Implements aggressive garbage collection to prevent CUDA OOM errors.\n",
    "* Robust Parsing: Regex-based fallbacks to handle model output variations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Environment Setup\n",
    "We first install the necessary dependencies. Qwen2.5-VL requires the latest transformers from GitHub and qwen-vl-utils for handling visual inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 1: Install required libraries\n",
    "!pip install -q git+https://github.com/huggingface/transformers --upgrade\n",
    "!pip install -q accelerate bitsandbytes pandas tqdm qwen-vl-utils\n",
    "print(\"Libraries installed! Please restart the kernel if this is the first run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Configuration & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 2: Import libraries and setup\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# Setup device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 3: Configuration\n",
    "class Config:\n",
    "    # UPDATE THIS PATH TO YOUR ACTUAL IMAGE DIRECTORY\n",
    "    IMAGE_DIR = \"/kaggle/input/poli-meme-decode-cuet-cse-fest/PoliMemeDecode/Test/Image\"\n",
    "    \n",
    "    # Qwen2.5-VL-7B-Instruct is highly recommended for this task (OCR + Reasoning)\n",
    "    MODEL_NAME = \"Qwen/Qwen2.5-VL-7B-Instruct\" \n",
    "    \n",
    "    OUTPUT_CSV = \"meme_analysis_optimized.csv\"\n",
    "    CHECKPOINT_CSV = \"meme_analysis_checkpoint.csv\"\n",
    "    \n",
    "    # Generation settings\n",
    "    MAX_NEW_TOKENS = 512\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load Quantized Model\n",
    "We load Qwen2.5-VL-7B-Instruct using BitsAndBytesConfig. This loads the model in 4-bit precision (NF4), reducing VRAM usage from ~15GB to ~6GB, leaving room for image processing context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 4: Load Model\n",
    "import torch\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig\n",
    "\n",
    "print(f\"Loading {config.MODEL_NAME}...\")\n",
    "\n",
    "# 1. Define Quantization Config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# 2. Load Processor\n",
    "processor = AutoProcessor.from_pretrained(config.MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "# 3. Load Model using AutoModelForVision2Seq\n",
    "# We use device_map=\"auto\" here which is generally safer with AutoModel + BitsAndBytes\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    config.MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\", \n",
    "    trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. System Prompt Engineering\n",
    "This is the core logic. We define a strict System Prompt that instructs the model to act as an expert analyst. It includes Guidelines for classification and Examples to ensure the output format matches the competition requirements exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 5: Define System Prompt\n",
    "\n",
    "# Placeholder <BLOCK> to avoid string escaping issues\n",
    "prompt_template = \"\"\"You are an expert analyst of Bangladeshi political and social memes. Your task is to analyze the meme image and output a JSON object.\n",
    "\n",
    "### OUTPUT FORMAT (JSON ONLY):\n",
    "You must output a single JSON object with these exact keys:\n",
    "1.  **Image_name**: (Leave empty)\n",
    "2.  **Humor**: Choose exactly ONE: 'Mockery', 'Sarcastic', 'Ironic', 'Satirical', 'Other'.\n",
    "3.  **Metaphor**: Choose exactly ONE: 'Both', 'Text', 'Image'.\n",
    "4.  **Meme_Explanation**: Describe the meme's meaning, context, and target.\n",
    "5.  **Metaphor_Object**: Identify the specific SUBJECT or ENTITY (e.g., \"Sheikh Hasina\", \"Vote Chori\").\n",
    "6.  **Political_Intensity**: Choose exactly ONE: 'High', 'Moderate', 'Low'.\n",
    "\n",
    "### CRITICAL RULES FOR 'Political_Intensity'\n",
    "* **HIGH**: You MUST select 'High' if the meme contains ANY of the following:\n",
    "    * **Names/Faces**: Sheikh Hasina, Khaleda Zia, Tarique Rahman, Yunus, Modi, Trump, Sajeeb Wazed Joy, Obaidul Quader, Palak.\n",
    "    * **Parties/Groups**: AL (Awami League), BNP, Jamaat, Shibir, BCL (Chhatra League), Hefazat.\n",
    "    * **Keywords**: \"Vote Chori\", \"August 15\", \"Genocide\", \"Dictator\", \"Fascist\", \"Regime\", \"Hartal\", \"1971\", \"Razakar\", \"Gonobhaban\".\n",
    "    * **State Forces**: Police, RAB, Army (only if depicted suppressing people or supporting a regime).\n",
    "    * *Rule of Thumb*: If it attacks a specific politician or party -> **HIGH**.\n",
    "\n",
    "* **MODERATE**: Use ONLY for:\n",
    "    * General social satire without naming names (e.g., \"Politicians are liars\" but no specific face).\n",
    "    * Institutional criticism (e.g., \"Bank corruption\", \"Education board\", \"Dhaka Traffic\", \"Price Hikes\").\n",
    "    * Cultural figures/Celebs (e.g., Shakib Al Hasan, Hero Alom) unless linked to a political party.\n",
    "\n",
    "* **LOW**: Use for:\n",
    "    * Relatable daily life (Exams, Relationships, Weather, Cricket sports).\n",
    "    * Pop culture/Movies.\n",
    "\n",
    "### GUIDELINES FOR 'Metaphor_Object'\n",
    "* **Identify the TARGET**: Do not describe the image. Describe who/what the image represents.\n",
    "* *Wrong*: \"Crying cat\"\n",
    "* *Right*: \"The Public\" or \"Failed Student\"\n",
    "* *Wrong*: \"Man laughing\"\n",
    "* *Right*: \"Sheikh Hasina\" or \"Corrupt Politician\"\n",
    "\n",
    "### EXAMPLES\n",
    "\n",
    "Example 1 (High - Named Leader):\n",
    "Output:\n",
    "<BLOCK>json\n",
    "{\n",
    "    \"Humor\": \"Satirical\",\n",
    "    \"Metaphor\": \"Both\",\n",
    "    \"Meme_Explanation\": \"Satirizes the idea of politicians like Hasina fleeing to India.\",\n",
    "    \"Metaphor_Object\": \"Sheikh Hasina\",\n",
    "    \"Political_Intensity\": \"High\"\n",
    "}\n",
    "<BLOCK>\n",
    "\n",
    "Example 2 (Moderate - General Issue):\n",
    "Output:\n",
    "<BLOCK>json\n",
    "{\n",
    "    \"Humor\": \"Ironic\",\n",
    "    \"Metaphor\": \"Image\",\n",
    "    \"Meme_Explanation\": \"Criticizes the general state of the country's fitness/infrastructure without naming a specific leader.\",\n",
    "    \"Metaphor_Object\": \"Country's fitness\",\n",
    "    \"Political_Intensity\": \"Moderate\"\n",
    "}\n",
    "<BLOCK>\n",
    "\n",
    "Example 3 (Low - Relatable):\n",
    "Output:\n",
    "<BLOCK>json\n",
    "{\n",
    "    \"Humor\": \"Other\",\n",
    "    \"Metaphor\": \"Text\",\n",
    "    \"Meme_Explanation\": \"Relatable humor about having a low balance in a mobile wallet.\",\n",
    "    \"Metaphor_Object\": \"Low account balance\",\n",
    "    \"Political_Intensity\": \"Low\"\n",
    "}\n",
    "<BLOCK>\n",
    "\n",
    "### YOUR TASK:\n",
    "Analyze the provided image and output the JSON.\n",
    "\"\"\"\n",
    "\n",
    "# Replace placeholder\n",
    "SYSTEM_PROMPT = prompt_template.replace(\"<BLOCK>\", \"```\")\n",
    "\n",
    "print(\"System Prompt Refined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Helper Functions\n",
    "We define two utility functions:\n",
    "\n",
    "\n",
    "* extract_json: Uses Regex to find valid JSON blocks within the model's textual response, handling cases where the model might add conversational filler.\n",
    "* analyze_image: Handles image resizing (to prevent OOM), tokenization, and inference generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 6: Processing Functions\n",
    "\n",
    "def extract_json(text):\n",
    "    \"\"\"Robust JSON extraction.\"\"\"\n",
    "    try:\n",
    "        # Try finding code blocks\n",
    "        match = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", text, re.DOTALL)\n",
    "        if match: return json.loads(match.group(1))\n",
    "        # Try finding raw braces\n",
    "        match = re.search(r\"(\\{.*\\})\", text, re.DOTALL)\n",
    "        if match: return json.loads(match.group(1))\n",
    "        return json.loads(text)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def analyze_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Resize large images to avoid OOM\n",
    "    max_dim = 1024\n",
    "    if max(image.size) > max_dim:\n",
    "        image.thumbnail((max_dim, max_dim))\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": SYSTEM_PROMPT}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": image}, {\"type\": \"text\", \"text\": \"Analyze this.\"}]}\n",
    "    ]\n",
    "\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    \n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=config.MAX_NEW_TOKENS)\n",
    "    \n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )[0]\n",
    "\n",
    "    return output_text\n",
    "\n",
    "print(\"Helper Functions Defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Execution Pipeline\n",
    "The main loop processes images sequentially. It includes:\n",
    "\n",
    "\n",
    "* Checkpointing: Saves progress every 10 images.\n",
    "* Garbage Collection: Explicitly clears GPU cache after every iteration to ensure stability.\n",
    "* Data Mapping: Maps the JSON output to the CSV columns required for submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-06T16:46:34.836Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 7: Process Images & Generate CSV\n",
    "\n",
    "import gc \n",
    "\n",
    "def main():\n",
    "    image_files = sorted([f for f in os.listdir(config.IMAGE_DIR) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
    "    results = []\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images.\")\n",
    "\n",
    "    # Resume from checkpoint\n",
    "    if os.path.exists(config.CHECKPOINT_CSV):\n",
    "        print(\"Resuming from checkpoint...\")\n",
    "        df_checkpoint = pd.read_csv(config.CHECKPOINT_CSV)\n",
    "        results = df_checkpoint.to_dict('records')\n",
    "        processed_files = set(df_checkpoint['Image_name'])\n",
    "        image_files = [f for f in image_files if f not in processed_files]\n",
    "\n",
    "    for idx, img_name in enumerate(tqdm(image_files)):\n",
    "        img_path = os.path.join(config.IMAGE_DIR, img_name)\n",
    "        \n",
    "        try:\n",
    "            # Memory Management\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            raw_response = analyze_image(img_path)\n",
    "            data = extract_json(raw_response)\n",
    "            \n",
    "            if not data:\n",
    "                entry = {\n",
    "                    \"Image_name\": img_name,\n",
    "                    \"Humor\": \"Other\",\n",
    "                    \"Metaphor\": \"Both\",\n",
    "                    \"Meme_Explanation\": \"Error parsing response.\",\n",
    "                    \"Metaphor_Object\": \"Unknown\",\n",
    "                    \"Political_Intensity\": \"Low\"\n",
    "                }\n",
    "            else:\n",
    "                entry = {\n",
    "                    \"Image_name\": img_name,\n",
    "                    \"Humor\": data.get(\"Humor\", \"Other\"),\n",
    "                    \"Metaphor\": data.get(\"Metaphor\", \"Both\"),\n",
    "                    \"Meme_Explanation\": data.get(\"Meme_Explanation\", \"\"),\n",
    "                    \"Metaphor_Object\": data.get(\"Metaphor_Object\", \"\"),\n",
    "                    \"Political_Intensity\": data.get(\"Political_Intensity\", \"Low\")\n",
    "                }\n",
    "            \n",
    "            # Print for verification\n",
    "            print(f\"\\n[Result for {img_name}]\")\n",
    "            print(f\"Object: {entry['Metaphor_Object']} | Intensity: {entry['Political_Intensity']}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "            results.append(entry)\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                pd.DataFrame(results).to_csv(config.CHECKPOINT_CSV, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_name}: {e}\")\n",
    "            torch.cuda.empty_cache()\n",
    "            continue\n",
    "\n",
    "    # Final Save with Correct Columns\n",
    "    final_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Target Columns\n",
    "    cols = [\"Image_name\", \"Humor\", \"Metaphor\", \"Meme_Explanation\", \"Metaphor_Object\", \"Political_Intensity\"]\n",
    "    \n",
    "    # Ensure all columns exist\n",
    "    for col in cols:\n",
    "        if col not in final_df.columns:\n",
    "            final_df[col] = \"\"\n",
    "            \n",
    "    final_df = final_df[cols]\n",
    "    final_df.to_csv(config.OUTPUT_CSV, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Analysis Complete. Saved to {config.OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Summary: Automated Political Meme Analysis with Qwen2.5-VL\n",
    "\n",
    "1. Automated Multimodal Analysis: The notebook implements an end-to-end pipeline using the Qwen2.5-VL-7B-Instruct model to interpret Bangladeshi political memes. It extracts complex semantic layers, classifying visual metaphors, humor types (e.g., Satire, Irony), and political intensity.\n",
    "2. Hardware Optimization: To function within the 16GB VRAM limit of Kaggle's Tesla T4 GPUs, the model is loaded with 4-bit quantization (NF4) using bitsandbytes. This reduces memory usage significantly while maintaining inference quality for visual reasoning tasks.\n",
    "3. Structured Output Generation: The workflow employs a specialized system prompt with few-shot examples to strictly enforce a JSON output schema. This ensures the model consistently generates clean, parseable data for specific CSV columns like Metaphor_Object and Political_Intensity instead of unstructured text.\n",
    "4. Robust Error Management: The pipeline includes aggressive memory management strategies, such as image resizing (max 1024px) and explicit garbage collection (gc.collect()), to prevent CUDA Out-of-Memory (OOM) errors. It also features checkpointing to save progress every 10 images, ensuring data integrity during long batch processes."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14664749,
     "sourceId": 124686,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
